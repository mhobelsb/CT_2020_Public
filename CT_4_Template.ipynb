{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CT Logo](img/ct_logo_small.png)\n",
    "# Vorlesung \"Computational Thinking\"        \n",
    "## Wrap-Up, Einführung in Pandas (1/2)\n",
    "#### Prof. Dr.-Ing. Martin Hobelsberger, CT_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lernziele dieser Einheit\n",
    "\n",
    "* Kurzes Wrap-Up\n",
    "* Einführung in die Bibliothek *Pandas* (1/2)\n",
    "    * *Teile dieses Notebooks wurden aus \"LearnDataSci: Python Pandas Tutorial\" ins Deutsche übersetzt*\n",
    "    * Zum weiterführenden Selbststudium bitte einen Blick auf folgende Links werfen: [Pandas Tutorials](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
    "    \n",
    "\n",
    "#### Was Sie bisher schon Wissen/Können sollten\n",
    "* Strukturiere Ein-/Ausgabe\n",
    "* Variablen\n",
    "* Datentypen (Arithmetische und Sequenzielle)\n",
    "* Arithmetische Ausdrücke und Vergleiche\n",
    "* Kontrollstrukturen (IF-Statement, For-/While-Schleife)\n",
    "* Dateien lesen/schreiben\n",
    "* Nützliche Funktionen (zip, enumerate, list comprehensions)\n",
    "* Funktionen\n",
    "* Dictionaries\n",
    "* map()/filter()\n",
    "* Lambda Expressions\n",
    "* Generatoren/Iteratoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "Kurze Wiederholung zu Themen der letzten Woche(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap-Up zu Iteratoren/Generatoren\n",
    "\n",
    "def datei_reader(datei_pfad):\n",
    "    '''\n",
    "    Liest eine Datei und liefert die Zeilen zurück\n",
    "    '''\n",
    "    r = open(datei_pfad)\n",
    "    return r.read().split(\"\\n\")\n",
    "\n",
    "lst = datei_reader('data/hallowelt.txt')\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Expression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Übung: Fibonacci Generator\n",
    "Schreiben Sie eine `Generator`-Funktion `def fibonacci(num)` für die Ausgabe einer Fibonacci Folge. Über den Eingabe-Parameter `num` soll die Anzahl der zu berechnenden Fibonacci Zahlen eingegeben werden können. Überprüfen Sie die Ausgabe über:\n",
    "\n",
    "```python\n",
    "def fibonacci(num):\n",
    "    #Your Code\n",
    "\n",
    "\n",
    "g_fib = fibonacci(10)\n",
    "for x in range(10):\n",
    "    print(next(g_fib)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übung Fibonacci Generator-Funktion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "![Pandas Logo](https://pbs.twimg.com/media/EHvNe7mXkAU0Myc?format=png&name=small)\n",
    "\n",
    "Die `Pandas`-Bibliothek ist eine der meist verwendeten Bibliotheken zur Datananalyse in Python. Die Bibliothek ist auf dem weiteren, essentiellen Modul `NumPy` aufgebaut und nutzt viele der Datenstrukturen aus diesem Modul. Pandas wird u.a. eingesetzt um: \n",
    "* sich schnell einen Überblick über große Datenmengen zu verschaffen\n",
    "* Datensätze zu bereinigen, \n",
    "* Datensätze zu transformieren und\n",
    "* zu analysieren\n",
    "\n",
    "Dazu werden Daten über die `Pandas`-Bibliothek eingelesen und als eigener **Datentyp `DataFrame`** gespeichert. Ein `DataFrame` ist im Grunde eine Tabelle mit der Sie:\n",
    "\n",
    "* Statistiken berechnen oder Fragen stellen, wie:\n",
    "    * Was ist der Durchschnitt, Minimum, Maximum von einer Spalte von Daten?\n",
    "    * Korrelieren zwei Spalten eines Datensatzes?\n",
    "    * Wie ist die Verteilung der Werte einer Spalte?\n",
    "* Daten bereinigen, wie zum Beispiel fehlende Werte (*NaN*) löschen oder Spalten/Zeilen filtern\n",
    "* Daten mit Hilfe von **Matplotlib**,  **Seaborn** oder anderen Visualisierungsmodulen visualisieren\n",
    "* Die bereinigten und bearbeiteten Daten wieder ablegen (z.B.: als CSV, in einer Datenbank oder als File)\n",
    "\n",
    "--> Es ist **essenziell für Sie als Data-Scientist** mit `Pandas` arbeiten zu können. Hilfreich für den Einstieg (und auch später!) sind sogennante \"Cheat Sheets\" wie z.B. dieses: [Pandas Cheat Sheet von pydata.org](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Grundkonzepte\n",
    "#### Erster Schritt - Installation\n",
    "\n",
    "`Pandas` ist keine Standard Bibliothek von Python und muss daher vor dem benutzen installiert werden. Dies können Sie lokal auf Ihrem PC mittels einem Paketverwaltungsprogramm namens **pip** machen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das \"!\" sorgt in einem Notebook dafür, dass die Zeile nicht als Code sondern als wie in einem Terminal ausgeführt wird.\n",
    "\n",
    "Eine weitere Möglichkeit ist es in Ihrem lokalen Terminal folgenden Befehl auszuführen:\n",
    "\n",
    "```\n",
    "python -m pip install pandas\n",
    "```\n",
    "\n",
    "Nach dem die Bibliothek erfolgreich installiert wurde, können wir sie benutzen / importieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import der Bibliothek\n",
    "import pandas as pd # Anmerkung: Es ist üblich pandas als \"pd\" zu importieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datentyp von pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die wichtigsten zwei Komponenten von pandas sind `Series` und `DataFrame`. Eine `Serie` ist im wesentlichen eine (Tabellen)Spalte wobei der `DataFrame` einer ganzen Tabelle (multi-dimensional), aufgebaut aus einer Sammlung von `Series`, entspricht. \n",
    "\n",
    "![CT Logo](img/CT_4/dataframe.png)\n",
    "\n",
    "`DataFrame` und `Series` unterstützen oft die selben Operationen (Berechnung von Statistiken, fehlende Werte entfernen, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erzeugen von DataFrames\n",
    "Es gibt viele Wege um einen `DataFrame` zu erzeugen. Eine Möglichkeit ist die Verwendung von `dict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfaches Beispiel zur Erzeugung eines DataFrames aus einem dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedes *(Schlüssel, Wert)* Element im Dictionary `data` entspricht nun einer Spalte im Dataframe `df`. Also Index wurde automatisch eine laufende Nummer angelegt. Dieser index ist standardmäßig immer eine Folge von Zahlen bei 0 beginnend. Er kann aber auch vom Entwickler definiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index aus Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf die Daten in einem *DataFrame* kann immer per **Index** zugegriffen werden. Dies funktioniert aber nicht über einen direkten Zugriff per '[]' sondern mittels der Funktion `.loc()` welcher für '**loc**ate' steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daten aus CSV einlesen\n",
    "Oft werden die Daten aus CSV Dateien eingelesen. Hierfür verwenden wir `read_csv()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundsätzlich immer über die Funktion .read_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daten aus JSON einlesen\n",
    "Neben dem sehr bekannten CSV-Datei Format gibt es auch noch viele andere Formate. Ein sehr oft genutztes und praktisches Format ist das sogenannte JSON-Format.\n",
    "\n",
    "**JSON** steht für *JavaScript Object Notation*. Der Aufbau ist ähnlich eines Dictionaries in Python.\n",
    "\n",
    "#### Beispiel\n",
    "\n",
    "\n",
    "```json\n",
    "{\"Name\":\n",
    "  {\"key\": value\n",
    "  ,\"key\": value\n",
    "  ,\"key\": value\n",
    "  }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "**Wichtig!** ist hier die Einhaltung der Klammerung und das Komma darf nicht vergessen beim sequentiellen Aufzählen der Key/Values Paaren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Beispiel mit Studierenden, Vorlesung und Noten ist ein wenig aufwändiger als einfaches Dictionary abzubilden. Daher können wir von `pandas` mit der Funktion `.to_json` ein JSON-string generieren lassen und uns diesen genauer anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Aufruf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orientation Argument: split|table|records|values|....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicher das Konvertierte als JSON-Datei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen mit selben Flag, wie die Formattierung innerhalb der Datei ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten werden oft nach der \"Bereinigung\" wieder gespeichert. Nutzen Sie dazu die von `Pandas` bereitgestellten Methoden wie z.B.: `df.to_csv()`, `df.to_json()` oder auch die Schnittstelle zu einer Datenbank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gängige Operaionen auf `DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten anzeigen\n",
    "Wie zu Beginn erwähnt, wird `pandas` oft eingesetzt um einen Überblick über die Daten zu bekommen auf welche dann Analysen ausgeführt werden. `DataFrames` stellen hierzu unzälige (!) Methoden für die Analysen und transformation zur Verfügung. Am besten fängt man hier natürlich an, seine Daten einfach mal ausgeben zu lassen und somit einen Überblick zu kriegen.\n",
    "\n",
    "Für die folgenden Beispiele wurden Teile dieses Notebooks aus *LearnDataSci: Python Pandas Tutorial* ins Deutsche übersetzt.  Als **Beispiel** benutzen wir einen [IMDB Film-Datensatz von kaggle](https://www.kaggle.com/PromptCloudHQ/imdb-data?select=IMDB-Movie-Data.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Daten als CSV und setzen der Index-Spalte auf den *Title*\n",
    "df = pd.read_csv(\"data/IMDB-Movie-Data.csv\", index_col=\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen der ersten Spalten des Datensatzes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.head()` zeigt dabei immer im Default die ersten **fünf** Zeilen des Dataframes an. Um mehr oder weniger anzuzeigen kann man der Methode einen Wert (z.B.: `df.head(10)`) übergeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen der letzten Spalten des Datensatzes\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informationen über die Daten\n",
    "\n",
    "Neben den angezeigten \"realen\" Werten aus dem Datensatz, gibt es natürlich auch noch sogenannte **Metadaten**., welche allgemeine Informationen über Größe, etc. beinhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einfacher Funktionsaufruf für genauere Informationen der Daten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Aufruf dieser Funktion `.info()`, sollte einer der ersten Aufrufe auf Ihrem Datensatz sein. Schließlich können hier wichtige viele Details herausgelesen werden, wie\n",
    "\n",
    "* Typen der Daten\n",
    "* Anzahl Zeilen/Spalten\n",
    "* Anzahl der non-null Werte\n",
    "* Größe der Daten (memory bezogen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich besitzt jedes **DataFrame** auch noch das Attribut `shape`, welches direkt angesprochen werden kann. Dieses Attribut gibt Auskunft über Zeilen (1000) und Spalten (11) in unserem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Entwickler benutzt `.shape` in der Regel sehr oft, wenn Daten bereinigt und aufgeräumt werden um schnell zu sehen, wie viele Zeilen oder Spalten gelöscht wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten bereinigen\n",
    "\n",
    "Es gibt mehrere Dinge, auf die Sie beim arbeiten mit großen Datensätzen immer achten sollten.\n",
    "\n",
    "* Doppelte Einträge sollten entfernt werden\n",
    "* Keine Sonderzeichen in Spaltenbezeichnern (Keys)\n",
    "* Spaltenbezeichner sollten das gleiche Format haben (lower/upper case)\n",
    "* Fehlende Werte sollten entfernt werden\n",
    "    * ganze Zeile wenn einzelne Werte fehlen, denn mit *NaN* kann nicht gerechnet werden und es führt zu Fehlern\n",
    "\n",
    "Schauen wir uns all diese Punkte folgend an und räumen den Datensatz auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt keine Doppelten Einträge, daher kopieren wir den Datensatz in sich selbst, sodass der `shape` sich verdoppelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplizieren der Daten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Entfernen von Duplikaten können wir einfach mit `drop_duplicates()` erreichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doppelte Einträge entfernen mit der Funktion .drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktionen `.append()` und `.drop_duplicates()` geben beide eine **Kopie** des originalen DataFrames zurück. Dies ist bei sehr vielen Funktionen von pandas zu beachten !!\n",
    "\n",
    "Um den originalen Datensatz direkt zu verändern um keine Kopie zu erzeugen, kann das Argument `inplace=True` übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erneutes duplizieren der Einträge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben `inplace` gibt es auch noch das Argument `keep`, welches der Funktion `.drop_duplicates()` übergeben werden kann.\n",
    "Hier gibt es 3 Optionen:\n",
    "\n",
    "* `first`: Entfernen aller Duplikate **außer** dem ersten Vorkommen -> ***default***\n",
    "* `last`: Entfernen aller Duplikate **außer** dem letzten\n",
    "* `False`: Entfernen aller Duplikate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da alle Zeilen Duplikate sind, werden folglich auch alle gelöscht und der shape ist somit *0*. Dieses Werkzeug kann man somit zum Beispiel benutzen, um alle vorhandenen Duplikate zu lokalisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spalten aufräumen\n",
    "Oft sind die Spaltennamen sehr durcheinander. Manche Namen bestehen aus in Klein-/Groß-Buchstaben, mit/ohne Leerzeichen, Sonderzeichen, etc. Damit die Selektierung per Spalte aber klar und einfach ist, sollten die Namen alle das gleiche Format haben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen der Spaltennamen\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Attribut `.columns` liefert ein Array mit allen Spaltennamen zurück.\n",
    "\n",
    "Diese Liste macht das Umbenennen sehr einfach, da diese durch eine angepasste Kopie seiner selbst ersetzt werden kann. Die Funktion hierfür heißt `.rename()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außerdem macht es meist Sinn, alle Schlüssel in Kleinbuchstaben zu schreiben. Dies passiert aber nicht durch ein ersetzen aller einzelnen Schlüssel per Hand sondern unter Anwendung einer `list comprehension`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension für lower case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umgang mit fehlenden Werten\n",
    "\n",
    "Während der Analyse eines Datensatzes werden Sie **fast immer** feststellen, dass Werte fehlen oder *null* sind. *Null* ist meist ein Platzhalter für nicht existente Werte.\n",
    "\n",
    "In Python und speziefisch in `pandas DataFrames` wird *null* als `None` oder NumPy's `np.nan` abgebildet. Beide \"Werte\" können unterschiedlich gehandhabt werden. \n",
    "\n",
    "Folgende Möglichkeiten gibt es mit fehlenden Werten umzugehen:\n",
    "* Löschen der Spalten oder Zeilen in denen null Werte existieren\n",
    "* *null* Werte mit *non-null* Werten ersetzen -> Diese Technik nennt man *imputation* (Anrechnung/Zuschreibung)\n",
    "\n",
    "Um die Anzahl aller *null* Werte über ein DataFrame zu berechnen, können Sie wie folgt vorgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.isnull()` liefert ein DataFrame, in welchem jede Zelle entweder `True` oder `False` entspricht. Dies ist abhängig davon ob die Zelle *null* ist.\n",
    "\n",
    "Um nun zu zählen, benutzen wir die Summenfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung**: Die Funktion `ìsnull()` ist eigenständig nicht sehr sinnvoll und wird meist in Kombination mit anderen Funktionen wie `.sum()` benutzt.\n",
    "\n",
    "Wie wir sehen, hat unser Datensatz **128** fehlende Werte für `revenue_millions` und **64** für `metascore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entfernen von null Werten\n",
    "\n",
    "Sie werden als Data Scientist noch oft mit dem Problem konforntiert werden, dass Sie fehlende Werte in einem Datensatz haben und vor der Entscheidung stehen werden, ob Sie *null* Werte ersetzen oder entfernen möchten. Diese Entscheidung verlangt einiges an Erfahrung im Umgang mit Daten und ein gutes Verständnis für die vorliegenden Daten.\n",
    "\n",
    "Wir in unserem Fall werden *null* Werte entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen von null Werten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `.dropna()` löscht jede **Zeile**, in welcher mindestens ein *null* Wert vorhanden ist. Auch hier liefert die Funktion wieder eine bearbeitete Kopie des Original zurück. Es kann aber auch wieder das Argument `inplace=True` übergeben werden.\n",
    "\n",
    "In unserem Fall wurden somit 128 Zeilen von *revenue_millions* und 64 Zeilen von *metascore* gelöscht. Dies erscheint aber ein wenig schade um die Daten, schließlich war immer nur ein einzelner Wert in der **Spalte** fehlend woraufhin die ganze **Zeile** entfernt wurde. Daher schauen wir uns gleich **imputation** ein wenig genauer an.\n",
    "\n",
    "Außerdem gäbe es auch die Möglichkeit, die Spalten anstatt der Zeilen zu entfernen. Dies passiert mittels des Arguments `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen der Spalten, in denen Werte == null sind\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Argument `axis=n` mit n = 1 betrifft die Spalten, n = 0 die Zeilen. Warum dies so ist, ist relativ simple zu verstehen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Rückgabe von `.shape` gibt ein Tuple zurück, welches in unserem Fall an Stelle mit dem index n=0 den Wert 1000 (Zeilen) und n=1 den Wert 11 (Spalten) besitzt. Über das Argument `axis=` wird somit nichts anderes festgesetzt, als der Index auf dem die Änderungen wirksam gemacht werden sollen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "\n",
    "Die Imputation wird verwendet, um Daten mit *null* Werten zu behalten.\n",
    "\n",
    "Manchmal kann ein fehlender Wert in einer einzigen Spalte dazu führen, dass ein verhältnismäßig großer Teil eines Datensatzes verloren geht, wenn alle *null* Werte einfach gelöscht werden. Um solch einen Fall zu vermeiden, kann der fehlende Wert mit dem **mean** (Durchschnitt) oder dem **median** (Mittelwert) der jeweiligen Spalte ersetzt werden.\n",
    "\n",
    "Als Beispiel ersetzen wir folgend die fehlenden Werte von *revenue_millions* mit dem Durchschnitt der Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Werte der revenue_millions holen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeigen der Werte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen des Means der ganzen Spalte mit Hilfe der Funktion .mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetzen aller null-Werte mit dem Durchschnitt Wert\n",
    "# Hierfür benutzen wir die Funktion .fillna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen ob das Ersetzen funktioniert hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Ansatz von Imputation ist somit, das ersetzen von null-Werten mit zum Beispiel dem Durchschnittswert der Spalte. Natürlich kann dies aber noch detailierte durchgeführt werden. Man könnte auch das komplette Datenset nach dem Genre der Filme sortieren, für jedes Genre den jeweiligen Durchschnitt berechnen und dann in den jeweiligen Untergliederungen die *null* Werte ersetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnis der Variablen\n",
    "\n",
    "Mittels `.describe()` können Sie eine Zusammenfassung der Verteilung aller kontinuierlichen Variablen eines DataFrames ausgeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe dieser Tabelle können Sie nun auf einen Blick sehen, in welchem Bereich die jeweiligen Variablen liegen und auch von welchem *type* sie sind. Wir unterscheiden:\n",
    "* Kontinuierliche Variablen (continuous variables)\n",
    "* Kategorische Variablen (categorical variables)\n",
    "\n",
    "Diese Informationen sind wichtig, wenn man die Daten Visualisieren möchte.\n",
    "\n",
    "`.describe()` kann auch auf kartegorische Variablen zugegriffen werden. Dazu muss die Methode auf die jeweiligen Spalten direkt angewendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf 'genre'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kann gut abgelesen werden:\n",
    "\n",
    "* Es gibt 207 einzigartige genres\n",
    "* Action,Adventure,Sci-Fi ist das am häufigsten vorkommende Genre\n",
    "* Das top Genre kommt ganze 50-mal vor\n",
    "\n",
    "Um zu schauen wie oft jeweils jedes *Genre* vorkommt, gibt es die Funktion `.value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abhängigkeiten zwischen kontinuierlichen Variablen\n",
    "\n",
    "Kontinuierliche Variablen (engl. continuous variables) sind Werte, welche auf bestimmte Art und Weise messbar sind und zwischen einem definiertem minimum und maximum liegen. In der Statistik beschreiben solche Variablen Daten und mehrere Variablen können einen Zusammenhang aufweisen, müssen aber nicht.\n",
    "\n",
    "\n",
    "In pandas gibt es dafür die Funktion `.corr()`, welche eine Korrelationsmatrix ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen, zeigt die Tabelle eine numerische Darstellung der Abhängigkeiten untereinander.\n",
    "\n",
    "* Positive Werte weisen auf eine positive Abhängigkeit -> Wenn ein Wert steigt, steigt auch der andere\n",
    "* Negative Werte weisen eine gegenteilige Abhängigkeit auf -> Wenn ein Wert steigt, fällt der andere.\n",
    "\n",
    "--> **1.0** stellt eine perfekte Abhängigkeit dar.\n",
    "\n",
    "Wie sie sehen, ist die Abhängigkeit untereinander verständlicherweise 1.0. Die Abhängigkeit zwischen `votes` und `revenue_millions` ist jedoch nicht so klar ersichtlich aber mit einem Werte von 0.6 auffallend.\n",
    "\n",
    "Um in größeren Tabellen schneller gewisse Abhängigkeiten zu erkennen, benutzt man meist sogenannte *scatterplots*. Aber dazu später (ein andern mal) mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame selektieren, extrahieren\n",
    "\n",
    "Alles was wir bisher gelernt haben, war ein kleiner Einstieg in die Arbeit eines Data-Scientists. Folgend betrachten wir noch weitere Methoden, welche Sie als Data-Scientist wohl regelmäßig verwenden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektieren einer Spalte als Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektieren einer Spalte als DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektieren mehrere Saplten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeilen\n",
    "\n",
    "Bei arbeiten mit Zeilen haben wir zwei Optionen:\n",
    "* `.loc` - **loc**ates anhand des Namens\n",
    "* `.iloc` - **loc**ates anhand eines numerischen Indices\n",
    "\n",
    "Vergessen Sie nicht, dass unsere Index Spalte die Film Title sind. Das heißt `loc()` bekommt in diesem Fall einen Film Title übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den Film Prometheus per Index selektieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` und `.iloc` funktionieren fast genau so, wie der normale Listen Zugriff, den Sie bisher kennengelernt haben. Daher schauen wir uns nun das Selektieren von mehreren Zeilen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein wichtiger Hinweis:\n",
    "* `.loc` impliziert den Film *Sing*\n",
    "* `.iloc` impliziert den letzten Wert **nicht**, welcher *Suicide Squad* an Stelle 4 ist\n",
    "\n",
    "Somit folgt `.iloc` den selben Regeln wie beim Listen Zugriff. Der letzte Index ist ausgenommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bedingte Selektion\n",
    "\n",
    "Was ist, wenn wir anhand von Bedingungen Selektieren möchten? Zum Beispiel, wie können wir alle Filme finden, welche von Ridley Scott sind und eine Bewertung größer/gleich 8.0 haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektieren mit Bedingung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schon bei der Funktion `isnull()`, ist die Rückgabe der Selektierung eine *Series* von True und False Werten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektierung der Werte, wo die Bedingung==True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu Beginn sind diese Art von Zugriffen evtl ein wenig verwirrend.. Sie können sich es aber wie folgt denken:\n",
    "\n",
    "> **SELECT** `df` **WHERE** `df[director]` **EQUALS** 'Ridley Scott'\n",
    "\n",
    "Folgend nun ein Zugriff mit einer numerischen Bedingung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter nach Bewertung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auch eine kombinierte Abfrage mit den Operatoren `|` für \"or\" und `&` für \"and\" bauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei solchen Abfragen müssen wir sicherstellen, dass wir mittels Klammern die Bedingung richtig gruppieren. Nur so weiß Python, wie die Bedingung auszuwerten ist.\n",
    "\n",
    "Wenn dies zu komplex bei manchen Bedingungen wird, können auch hier Hilfsmethoden wie `.isin()` verwendet werden, wodurch der Aufbau wesentlich übersichtlicher wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Übung**\n",
    "Wir möchten alle Filme welche zwischen 2005 und 2010 erschienen sind mit einer Bewertung größer als 8.0 aber einen niedrigeren Umsatz als 25 Prozent aller aufweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwenden von Funktionen\n",
    "\n",
    "Über ein `pandas DataFrame` oder `Series` kann wie über eine Liste iteriert werden. Dies ist meist, gerade bei großen Datensätzen, langsam. \n",
    "\n",
    "Um dies effizienter zu gestalten, kann eine Funktion mit `apply()` auf den Datensatz \"angewendet\" werden. Als Beispiel können wir jeden Film mit einer höheren Bewertung als 8.0 als \"good\" bezeichnen und alle anderen als \"bad\" und diese umgewandelten Werte als neue Spalte speichern.\n",
    "\n",
    "Dafür erstellen wir als erstes eine Funktion, die die Umwandlung durchführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_func(x):\n",
    "    if x >= 8.0:\n",
    "        return \"good\"\n",
    "    else:\n",
    "        return \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwenden der Funktion auf das komplette DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `.apply()` Methode nimmt jeden Wert aus der Spalte `rating`, ruft mit diesem die Funktion `rating_func` auf und erstellt eine neue Series. Diese Series wird der neuen Spalte `rating_category` hinzugefügt.\n",
    "\n",
    "Neben normalen Funktionen können auch anonyme Funktionen (Lambda Expressions) benutzt werden. Im folgenden das selbe nochmal mit einem Lambda Ausdruck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bemerkung**:\n",
    "\n",
    "Die Benutzung von `apply()` ist immer viel schneller als manuell über die Zeilen zu iterieren, da Pandas *Vektorisierung* verwendet.\n",
    "\n",
    "> Vectorization: a style of computer programming where operations are applied to whole arrays instead of individual elements —[Wikipedia](https://en.wikipedia.org/wiki/Vectorization)\n",
    "\n",
    "Dies kann man gut im Bereich von Natural Language Processing (NLP) sehen. Hier muss im ersten Schritt immer viel Texte schnell bearbeitet und angepasst werden um fürs machine learning vorbereitet zu sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einblick ins Plotting\n",
    "\n",
    "Ein weiterer Vorteil von pandas ist, dass die Bibliothek sehr gut mit Matplotlib arbeiten kann und dies viel Mühe und Arbeit spart.\n",
    "\n",
    "Folgend eine Visualisierung von einem Teil unserer Werte mit der Bibliothek Matplotlib (`pip install matplotlib`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20, 'figure.figsize': (10, 8)}) # setzen der Schriftgröße und plot Größe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir möchten nun die vorher angesprochene Abhängigkeit von `rating` und `revenues` in einem *scatterplot* abbilden. \n",
    "\n",
    "**Hinweis:** \n",
    "* Für Kategorische Variablen eignen sich Balkendiagramme und Boxplots\n",
    "* Für Kontinuierliche Variablen eignen sich Histogramme, Scatterplots, Liniendiagramme oder auch Boxplots\n",
    "\n",
    "Dafür müssen wir nichts machen, als die Funktion `.plot()` auf unserem DataFrame aufzurufen und ein paar Argumente übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung**: Ist Ihnen das Semikolon aufgefallen? Dies ist kein Syntax Fehler! Wir möchten nur die Ausgabe von dieser Code Zeile **nicht** angezeigt bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mit Ausgabe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ein einfaches Histogram basierend auf der Spalte rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und genauso weiter können wir nun alle möglichen Arten von plots die im DataScience Bereich benötigt werden, darstellen. Welche Arten es alle gibt, kann wie immer in der Dokumentation der Funktion `.plot()` oder in der Doku der Matplotlib nachgelesen werden.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammenfassung\n",
    "\n",
    "Das Verstehen, Bereinigen, Transformieren und Visualisieren von Daten mit pandas in python ist eine wichtige Aufgabe als Data Scientist. Allein das Bereinigen der Daten kann meist bis zu 80% Ihrer Arbeit ausmachen.\n",
    "\n",
    "Es gibt sehr viele sehr umfangreiche Tutorials im Netz, falls Sie privat Lust und Laune haben, sich noch viel näher mit dem Thema zu beschäftigen. Kaggle ist zum Beispiel immer eine gute Anlaufstelle um sich selbst an einem Datensatz auszuprobieren und an diesem zu wachsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
