{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CT Logo](img/ct_logo_small.png)\n",
    "# Vorlesung \"Computational Thinking\"        \n",
    "## Einführung in Pandas (2/2)\n",
    "#### Prof. Dr.-Ing. Martin Hobelsberger, CT_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lernziele dieser Einheit\n",
    "\n",
    "* Einführung in die Bibliothek *Pandas* (2/2)\n",
    "\n",
    "#### Was Sie bisher schon Wissen/Können sollten\n",
    "* Strukturiere Ein-/Ausgabe\n",
    "* Variablen\n",
    "* Datentypen (Arithmetische und Sequenzielle)\n",
    "* Arithmetische Ausdrücke und Vergleiche\n",
    "* Kontrollstrukturen (IF-Statement, For-/While-Schleife)\n",
    "* Dateien lesen/schreiben\n",
    "* Nützliche Funktionen (zip, enumerate, list comprehensions)\n",
    "* Funktionen\n",
    "* Dictionaries\n",
    "* map()/filter()\n",
    "* Lambda Expressions\n",
    "* Generatoren/Iteratoren\n",
    "* Grundfunktionen von Pandas\n",
    "    * Einfache Datenanalyse mittels Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings für CT_5\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas (2/2)\n",
    "\n",
    "![Pandas Logo](https://pbs.twimg.com/media/EHvNe7mXkAU0Myc?format=png&name=small)\n",
    "\n",
    "Bisher haben wir die grunlegenden Funktionen von Pandas gelernt. Wir können Datensätze einsehen, diese Bereinigen und Aufräumen und anschließend sogar in einem einfachen Graphen Abhängigkeiten darstellen. Als Data Scientist müssen aber auch komplexere Aufgaben auf einem Datensatz erledigt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir laden wieder unseren IMDB-Film Datensatz und werden folgend mit diesen Daten weiter arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/IMDB-Movie-Data.csv\", index_col=\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sortieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Ihnen vielleicht schon im letzten Teil aufgefallen ist, sind die Daten anhand der ersten vorkommenden Spalte sortiert. Also dem **Rank**. Aber was ist, wenn wir die Daten eigentlich alphabetisch nach dem **Director** sortieren möchten?\n",
    "\n",
    "Für Sortierungen gibt es die Funktion `.sort_values(by=)`. Mit dem Argument `by=` kann der Spaltenname angegeben werden, nachdem sortiert werden soll. Außerdem kann auch das argument `ascending=` angegeben werden. Default Wert ist hier *True*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortieren nach 'Director'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was aber, wenn es einen Director gibt, der mehrere Filme produziert hat? (Ist schließlich nicht ganz unwahrscheinlich..)\n",
    "\n",
    "Dann sollten wir noch mehr Spalten als **Director** definieren, nach denen sortiert wird, wenn dieser Fall auftritt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortieren nach mehreren Spalten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zu sehen ist, sidn die Filme *The Big Short* und *The Other Guys* vom Director *Adam McKay* nun zusätzlich absteigend nach dem Jahr sortiert. Und sollte dieses Argument in manchen Fällen auch nicht ausreichen, dann wird bei unserer Angabe final auch noch nach der Laufzeit absteigend sortiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gruppieren\n",
    "Gruppieren eines `DataFrame` und Anwenden verschiedener Operationen. Aufruf über `.groupby()` mit den Spalten die Gruppiert werden sollen und den Spalten die aggregiert werden sollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppieren von Directors mit Ausgabe des Umsatzes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oft wird ein \"Prozess\" im Zuge der Gruppierung angewendet der sich **split-apply-combine** nennt. Dabei werden drei Schritte ausgeführt:\n",
    "1. *Split* einer Tabelle in Gruppen\n",
    "2. *Apply* (Anwenden) von Operationen auf jeder der kleineren Tabellen\n",
    "3. *Combine* (Kombinieren) der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datentypen in Pandas\n",
    "\n",
    "Bevor wir in den Datensatz einsteigen noch einmal eine kurze Wiederholung von allen Datentypen, die wir in python haben:\n",
    "\n",
    "* `object`: Benutzt bei Strings (Sequenz von Charaktern)\n",
    "* `int64`: Ganzen Zahlen\n",
    "* `float64`: Dezimal Zahlen\n",
    "* `bool`: Werte die nur True/False sein können\n",
    "* `datetime64`: Datum und Zeit Werte\n",
    "* `timedelta`: Stellt Differenz von datetime dar\n",
    "* `category`: kategorisierte Darstellung von Werten (Enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige von zufälligen 5 Werten aus dem Datensatz\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in Teil 1 erwähnt, wollen wir uns zu Beginn immer einen Überblick verschaffen (auch wenn wir den Datensatz eventuell schon kennen). Dafür sind die Funktionen `.sample()`, `.info()` und `.describe()` sehr hilfreich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in der Ausgabe zu sehen, hat pandas den Datensatz eingelesen und so gut wie möglich vorläufig jeder Spalte einen Datentyp zugewiesen. Man hätte hier aber auch spezifischere Tpyen angeben können.\n",
    "\n",
    "Zum Beispiel trifft auf die Spalte *Genre* der Typ `category` gut zu. Also ändern wie dies kurz ab mit der Funktion `.astype()`. Pandas bietet Hilfsfunktionen für die komplizierteren Konvertierungen: `pd.to_numeric` und `pd.to_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre in category umwandeln\n",
    "\n",
    "df['Genre'] = df['Genre'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schauen wir uns das Ergebnis der Änderung an\n",
    "df.dtypes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Konvertierungen mittels `.astype()` oder `pandas` Funktionen wie `to_numeric()` können immer **Fehler** auftreten, wenn einzelne Werte im Datensatz nicht dem Typ entsprechen, in den Konvertiert werden soll. Zum Beispiel könnten Zahlen in einem Datensatz als `object` eingelesen worden sein, obwohl sie auch als `int64` abgebildet werden könnten. Bei der Konvertierung kann es aber passieren, das ein paar Werte von z.B. 1000 Einträgen doch Strings sind und diese nicht in `int64` konvertiert werden können.\n",
    "\n",
    "Um mit solchen Fehler umgehen zu können, gibt es ein weiteres Argument für die Funktionen: `errors=`.\n",
    "\n",
    "Mittels dieses Arguments kann angegeben werden, wie mit Fehlern umgegangen werden soll.\n",
    "\n",
    "* `errors=ignore`: Ignorieren der Werte, wenn Fehler auftreten **default**\n",
    "* `errors=coerce`: Nicht Konvertierbare Werte werden in `np.nan` Werte umgewandelt\n",
    "\n",
    "Wie bei vielen Problemen gibt es auch hier keine perfekte Lösung, sondern in jedem Fall muss individuell Entschieden werden, wie mit solchen Werten umgegangen werden soll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nützliche Zugriffsattribute für bestimmte Datentypen\n",
    "\n",
    "Pandas Zugriffsattribute können als Schnittstelle zu Methoden gesehen werden, welche spezifisch für den Typ entwickelt sind. Das heißt die Methoden sind spezialisiert und dienen nur **einer einzigen** Aufgabe. Für diese bestimmten Aufgaben sind sie ausgezeichnet und äußerst prägnant.\n",
    "\n",
    "Es gibt drei Attribute dieser Art:\n",
    "\n",
    "* `dt`: datetime\n",
    "* `str`: string\n",
    "* `cat`: category\n",
    "\n",
    "Sie können wie folgt aufgerufen werden: `.<accessor>.method` auf einer beliebigen Spalte, zum Beispiel `df['Genre'].cat.categories`.\n",
    "\n",
    "Das ganze nun etwas im Detail..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribut - dt\n",
    "\n",
    "* `date`: gibt ein datetime Wert zurück"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Methoden stehen unter `.dt` zur Verfügung:\n",
    "\n",
    "* `date`: liefert Datum des datetime Wertes\n",
    "* `weekday_name`: liefert den Namen des Wochentages\n",
    "* `month_name()`: liefert den Namen des Monats (**MUSS** im Vergleich zu `weekday_name` mit Klammern aufgerufen werden)\n",
    "* `days_in_month`: liefer die \"Tageszahl\"\n",
    "* `nanosecond`, `microsecond`, `second`, `minute`, `hour`, `day`, `week`, `month`, `quarter`, `year`\n",
    "* `is_leap_year`, `is_month_start`, `is_month_end`, `is_quarter_start`, `is_quarter_end`, `is_year_start`, `is_year_end`: gibt *True* oder *False* für jeden Wert zurück\n",
    "* `tp_pydatetime()`: wandelt die Werte in python `datetime`\n",
    "* `to_period(<PERIOD>)`: wandelt ein datetime in eine angegebene periode um. Periods: (W, M, Q, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribut - str\n",
    "\n",
    "Dieses Attribut erleichtert den Umgang mit Strings. Vorallem, da durch dieses Hilfsattribut die Funktionsaufrufe und somit der Code wesentlich lesbarer wird, wie wenn man mit einer String-Bibliothek arbeiten würde.\n",
    "\n",
    "Folgende Methoden sind erreichbar:\n",
    "\n",
    "* `.lower()`, `.upper()`: ändern von Groß- und Kleinschreibung\n",
    "* `.ljust(width)`, `.rjust(width)`, `.center(width)`, `.zfill(width)`: zur Verwaltung von der Positionierung der Strings\n",
    "* `.startswith(<substr>)`, `.endswith(<substr>)`, `.contains(<substr>)`: prüfen ob ein substring vorhanden ist\n",
    "* `.swapcase()`, `.repeat(times)`: Ganz ehrlich? Easter Egg.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folgend ein paar Beispiele für die Anwendung von .str. Methoden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positionierung von Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhandensein von substrings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filme in denen Will Smith mit spielt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribut - cat\n",
    "\n",
    "Dieses Attribut bietet Funktionalität für den Umgang mit Attributen des Typs `category`.\n",
    "\n",
    "Folgende Methoden werden bereitgestellt:\n",
    "\n",
    "* `.ordered`: gibt an, ob die Spalte sortiert ist \n",
    "* `.categories`: gibt die Kategorien zurück\n",
    "* `.codes`: konvertiert Kategorien in numerische Repräsentation (später mal sehr hilfreich im machine learning Bereich !!)\n",
    "* `.reorder_categories()`: verändert die vorhandene Reihenfolge der Kategorien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel zur Anwendung von .cat.\n",
    "# Wir erinnern uns: unsere Spalte 'Genre' wurde in den Typen 'category' umgewandelt\n",
    "df['Genre'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].cat.ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe aller Kategorien, die es gibt in unserem Film Datensatz\n",
    "df['Genre'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.reorder_categories` ist an unserem Beispiel leider schlecht zu zeigen. Die Idee ist es, eine Reihenfolge anzugeben, sodass die Ausgabe von `.cat.codes` der angegebene Reihenfolge entspricht und nicht mehr der 'Zufälligen'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
