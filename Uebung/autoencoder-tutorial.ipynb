{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalieerkennung mit Autoencodern\n",
    "**Jan-Philipp Schulze, Fraunhofer AISEC, 2020**\n",
    "\n",
    "In diesem Tutorial wollen wir Anomalien mit einem speziellen Neuronalen Netz (NN), dem Autoencoder, erkennen.\n",
    "Autoencoder lernen, die Eingabe zu komprimieren und am Ende zu rekonstruieren.\n",
    "Trainiert man sie nur auf normalen Daten, so haben sie Schwierigkeiten, anomale Daten wiederherzustellen - dies kann man messen und zur Anomalieerkennung benutzen.\n",
    "\n",
    "Währenddessen lernen wir die gängige Machine Learning (ML) Pipeline kennen.\n",
    "Diese besteht aus:\n",
    "* **Daten einlesen** (read): Kennenlernen der Daten, z.B. was ist enthalten, wie sind sie verteilt?\n",
    "* **Daten vorverarbeiten** (preprocess): Aufbereitung der Daten, sodass der ML Algorithmus sie verarbeiten kann.\n",
    "* **ML Modell trainieren** (train): Das ML Modell \"lernt\" aus den Daten.\n",
    "* **ML Modell nutzen** (predict): Vorhersage treffen.\n",
    "* **Leistung evaluieren** (evaluate): Performance des ML Modells abschätzen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Daten einlesen\n",
    "Um die Ergebnisse zu visualisieren, benutzen wir kein klassisches Anomalieerkennungsdatensatz, sondern einen bekannten Datensatz aus der Bildverarbeitung: Fashion-MNIST.\n",
    "Dieser ist bereits bei TF2 mit dabei.\n",
    "\n",
    "Wie in ML üblich bezeichnet ``x`` die Eingabe (hier: das Bild) und ``y`` die Ausgabe (hier: eine Klasse).\n",
    "Wir unterscheiden zwischen Daten auf denen wir trainieren und auf denen wir testen.\n",
    "In echten ML Szenarios fernab dieses Tutorials sollten wir darüberhinaus einen Datensatz zum Validieren erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgaben\n",
    "1. Lernt die Daten kennen:\n",
    "    1. Wie viele Samples haben wir? Was sind ihre Dimensionen?\n",
    "    2. Welche Werte haben die Daten? Warum?\n",
    "2. Filtert nach Daten aus der Klasse 0. Was zeigen sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Euer Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorverarbeiten\n",
    "NN lernen über Gradienten.\n",
    "Diese haben bessere Eigenschaften, wenn die Daten skaliert bzw. normalisiert werden.\n",
    "Ohne Preprocessing kann es sein, dass das NN nicht oder nur sehr langsam lernt.\n",
    "\n",
    "### Aufgaben\n",
    "1. Skaliere die Daten, sodass sie zwischen 0 und 1 liegen.\n",
    "2. Unser simpler Autoencoder akzeptiert nur 1-dimensionale Eingaben. Formatiere entsprechend.\n",
    "3. Für unsere Anomalieerkennung nehmen wir alle Bilder aus Klasse 0 als normal an, alle aus 1 als anomal.\n",
    "    1. Reduziere den Trainingsdatensatz auf die Klasse 0.\n",
    "    2. Reduziere den Testdatensatz auf Klasse 0 und 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Euer Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ML Modell trainieren\n",
    "Während des Trainings wird das ML Modell auf die Trainingsdaten angepasst:\n",
    "In unserem Fall lernt der Autoencoder, die Trainingsdaten zu rekonstruieren.\n",
    "\n",
    "### Deep Learning mit TensorFlow2\n",
    "Wir bauen unseren Autoencoder in TensorFlow2 (TF2) auf.\n",
    "TF2 kennt drei Arten, ein NN aufzubauen:\n",
    "* Sequentiell\n",
    "* Funktional\n",
    "* Subklassen\n",
    "\n",
    "Wir werden eine Mischung aus Sequenzen und Subklassen verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.m_encoder = None\n",
    "        self.m_decoder = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Construct the encoder\n",
    "        m_encoder = tf.keras.Sequential(name=\"encoder\")\n",
    "        m_encoder.add(tf.keras.layers.Dense(800, activation=\"relu\", input_shape=input_shape))\n",
    "        m_encoder.add(tf.keras.layers.Dense(400, activation=\"relu\"))\n",
    "        m_encoder.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "\n",
    "        self.m_encoder = m_encoder\n",
    "\n",
    "        # Construct the decoder\n",
    "        m_decoder = tf.keras.Sequential(name=\"decoder\")\n",
    "        m_decoder.add(tf.keras.layers.Dense(400, activation=\"relu\", input_shape=m_encoder.output_shape[1:]))\n",
    "        m_decoder.add(tf.keras.layers.Dense(800, activation=\"relu\"))\n",
    "        m_decoder.add(tf.keras.layers.Dense(input_shape[-1], activation=\"sigmoid\"))\n",
    "\n",
    "        self.m_decoder = m_decoder\n",
    "\n",
    "    def call(self, input_data, training=None, mask=None):\n",
    "        # Concatenate our autoencoder\n",
    "        t_code = self.m_encoder(input_data, training=training, mask=mask)\n",
    "        t_out = self.m_decoder(t_code, training=training, mask=mask)\n",
    "\n",
    "        return t_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir den Autoencoder trainieren können, müssen wir noch angeben, welches Ziel das Modell hat:\n",
    "Dazu definiert man eine Fehlerfunktion (Loss-Function).\n",
    "Beim Autoencoder wollen wir die Eingabe möglichst genau rekonstruiert haben.\n",
    "Subklassen von ``tf.keras.Model`` haben darüberhinaus eine ``fit``-Funktion, die zum Trainieren benutzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create an autoencoder\n",
    "autoencoder = Autoencoder()\n",
    "# Define the loss\n",
    "autoencoder.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "# Train\n",
    "autoencoder.fit(x=x_train, y=x_train, epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Modell nutzen\n",
    "Wir haben nun einen Autoencoder, der gut mit den Trainingsdaten umgehen kann.\n",
    "Wie sieht es jedoch auf den bisher unbekannten Testdaten aus?\n",
    "\n",
    "### Aufgaben\n",
    "1. Benutze die ``predict``-Funktion, um:\n",
    "    1. Ein Sample der normalen Klasse 0 zu rekonstruieren,\n",
    "    2. Ein Sample der anomalen Klasse 1 zu rekonstruieren.\n",
    "2. Plotte die Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Euer Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Anomalien finden\n",
    "Wie wir gesehen haben, hat der Autoencoder Probleme, anomale Eingaben zu rekonstruieren.\n",
    "Dies können wir zur Anomalieerkennung nutzen: Wir messen den Abstand zwischen der Eingabe und der Ausgabe.\n",
    "Für anomale Eingaben sollte dieser höher liegen.\n",
    "\n",
    "In diesem Falle sagen wir: Alles, was weit weg vom normalen Rekonstruktionsfehler liegt, ist anomal.\n",
    "Wir modellieren dies mithilfe einer Gaussverteilung.\n",
    "Beachtet: Wir müssten dies eigentlich auf dem Validierungsdatensatz machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normal reconstruction error\n",
    "re_normal = np.mean(np.square(x_norm - pred_norm), axis=1)\n",
    "# Anomaly threshold based on a Gaussian\n",
    "re_normal_mean = np.mean(re_normal)\n",
    "re_normal_std = np.std(re_normal)\n",
    "anom_thresh = re_normal_mean + re_normal_std\n",
    "\n",
    "# Reconstruction error of unknown samples\n",
    "re_unknown = np.mean(np.square(x_test - pred_test), axis=1)\n",
    "y_unknown = np.zeros_like(y_test)\n",
    "y_unknown[re_unknown > anom_thresh] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Leistung evaluieren\n",
    "Aus dem vorherigen Schritt haben wir eine Reihe an Vorhersagen: 0 für normal, 1 für anomal.\n",
    "Aber haben wir eine gute Anomalieerkennung gebaut?\n",
    "Dies evaluieren wir durch Metriken.\n",
    "In der Vorlesung habt ihr Precision and Recall kennengelernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "# Compute metrics\n",
    "pred_precision = precision_score(y_true=y_test, y_pred=y_unknown)\n",
    "pred_recall = recall_score(y_true=y_test, y_pred=y_unknown)\n",
    "\n",
    "print(f\"Precision: {pred_precision:.3f}\")\n",
    "print(f\"Recall: {pred_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
